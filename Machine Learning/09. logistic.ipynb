{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시그모이드 함수 통과시키고\n",
    "# cost 함수가 로그"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.desmos.com/?lang=ko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로지스틱 회귀 (Logistic Regression)\n",
    "\n",
    "* 로지스틱 회귀는 이름에 회귀라는 단어가 들어가지만, 가능한 클래스가 2개인 이진 분류를 위한 모델\n",
    "* 로지스틱 회귀의 예측 함수 정의\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}} \\\\\n",
    "\\hat{y} = \\sigma(b + w x) \n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\hat{y} = \\sigma(b + w_1 x_1 + ... + w_p x_p)\n",
    "\\end{equation}\n",
    "\n",
    "  + $\\sigma$: 시그모이드 함수\n",
    "  \n",
    "* 로지스틱 회귀 모델은 선형 회귀 모델에 시그모이드 함수를 적용\n",
    "\n",
    "* 로지스틱 회귀의 학습 목표는 다음과 같은 목적 함수를 최소화 하는 파라미터 $w$를 찾는 것\n",
    "\n",
    "\\begin{equation}\n",
    "BinaryCrossEntropy = -\\frac{1}{N}\\sum_{i=1}^{N}y_i\\log(\\hat{y}_i) + (1-y_i)\\log(1-\\hat{y}_i)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y * -np.log(hx) + (1 - y) * -np.log(1 - hx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공부한 시간, 출석일수\n",
    "\n",
    "x_data = np.array( [[1,3],[2,2],[3,1],[4,6],[5,5],[6,4]] )\n",
    "y_data = np.array( [0,0,0,1,1,1] ) # 합불 # 피쳐는 매트릭스로 줘야 하지만 라벨은 안 그래도 됨!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logi = LogisticRegression()\n",
    "model_logi.fit(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78341156, 0.78341156]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다중 - 피쳐가 두 개\n",
    "\n",
    "model_logi.coef_ # 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.48382067])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logi.intercept_ # 절편"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+math.e**-z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.9171181]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 연속 데이터 예측은 여기서 끝남\n",
    "\n",
    "z = np.matmul( [[6, 6]], model_logi.coef_.reshape(-1, 1)) + model_logi.intercept_\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98048986]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로지스틱은 0아니면 1이니까 시그모이드 함수를 통과시킴!\n",
    "\n",
    "sigmoid(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 로지스틱 메소드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01951014, 0.98048986]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logi.predict_proba([[6, 6]]) # 0일 확률이 0.02, 1일 확률이 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logi.predict_proba([[6, 6]]).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logi.predict([[6, 6]]) # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logi.predict([[1,1],[6, 6]])\n",
    "\n",
    "# 불합격 / 합격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98048756, 0.01951244],\n",
       "       [0.01951014, 0.98048986]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logi.predict_proba([[1,1],[6, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logi.predict_proba([[1,1],[6, 6]]).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logi.score(x_data, y_data) # 정확도 accuracy # 예측값과 실제 결과의 평균값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = model_logi.predict(x_data) # 예측값\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p == y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p == y_data).mean() # model_logi.score(x_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류에서는 단순히 정확도를 가지고 판단하지 않는다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic 파라미터 (로지스틱은 학습에 의한 것!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "penalty : str, ‘l1’, ‘l2’, ‘elasticnet’ or ‘none’, optional (default=’l2’)\n",
    "\n",
    "  l1: 맨하튼 거리, 오차 = 오차 + alpha * (|w1| + |w2|) <br>\n",
    "  l2: 유클리디안 거리의 제곱, 오차 = 오차 + alpha * (W1^2 + w2^2)\n",
    "  가중치 규제 (특성 수 줄이기, 과대적합 방지) <br>\n",
    "  none 면 가중치 규제 미사용 <br>\n",
    "\n",
    "  loss = loss + regularization strength X 가중치의 l1 혹은 l2 거리 (가중치 규제(과적합 방지))<br>\n",
    "  가중치가 커지지 못하게 하기 (과적합 방지)<br>\n",
    "\n",
    "C : float, optional (default=1.0)<br>\n",
    "  alpha 의 역수<br>\n",
    "  alpha 는 클수록 가중치 규제, 작을수록 정확하게 (과적합)<br>\n",
    "\n",
    "  regularization strength(가중치 규제 항목에 곱해지는 값)의 역수 (과적합 방지)\n",
    "  디폴트 1.0\n",
    "  역수기 때문에 작을수록 과적합 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### penalty:L1 혹은 L2 제약조건의 강도를 설정  \n",
    "\n",
    "#### alpha: 높은 알파 값을 설정할 수록, 높은 제약조건을 설정하는 것\n",
    "\n",
    "#### C: \n",
    "cost function의 C를 의미하는 것이며,\n",
    "C의 경우에는 높은 C를 설정할 수록, 낮은 강도의 제약조건이 설정되고\n",
    "낮은 C를 설정할 수록, 높은 강도의 제약조건이 설정\n",
    "\n",
    "### solver : \n",
    "liblinear:L1제약조건, L2제약조건 두 가지를 모두 지원하며, 이것은 작은 데이터에 적합한 알고리즘. <br>\n",
    "sag, saga: 이것을 확률적경사하강법을 기반으로 하기에 대용량 데이터에 적합한 알고이름이라고 하며, <br>\n",
    "sag는 L1 제약조건만을 지원하고, saga는 L1, L2 제약조건 둘 다 지원함.\n",
    "\n",
    "<div style=\"color:red\">회귀알고리즘에서 ridge와 lasso와 계수를 다루는 방법이 유사하다고 보면 된다.\n",
    "L1규제는 lasso처럼 계수를 0으로도 만들 수 있고,\n",
    "L2규제는 ridge처럼 계수를 0으로 만들진 않지만 영향력이 작으면 0에 가까운 값을 만들어 회귀식을 구성하게 된다.\n",
    "</div>\n",
    "\n",
    "#### newton-cg, lbfgs (sag, saga)  이것은 멀티클래스의 분류 모델에 쓰는 것\n",
    "\n",
    "현재까지는 이 중에서 lbfgs 알고리즘이 가장 성능이 좋다고 알려져 있고, newton-cg, lbfgs 도 L2제약조건만 지원함.<br>\n",
    "결국 sag는 L1만 지원하고, newton-cg, saga, lbfgs 세 가지가 L2만 지원하고, <br>\n",
    "liblinear, saga가 L1, L2 둘 다 지원<br>\n",
    "\n",
    "#### penalty :  L1, L2 제약조건을 설정하는 하이퍼 파라미터이고, default는 L2\n",
    "    \n",
    "#### class_weight :데이터에 직접 가중치를 설정하여 학습의 강도를 다르게 할 수 있는 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <연습문제>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data5/pima-indians-diabetes.data.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정보 1 : 과거 임신 횟수 (pregnant)\n",
    "\n",
    "정보 2 : 포도당 부하 검사 2시간 후 공복 혈당 농도 (plasma)\n",
    "\n",
    "정보 3 : 확장기 혈압 (pressure)\n",
    "\n",
    "정보 4 : 삼두근 피부 주름 두께 (thickness)\n",
    "\n",
    "정보 5 : 혈정 인슐린 (insulin)\n",
    "\n",
    "정보 6 : 체질량 지수 (BMI)\n",
    "\n",
    "정보 7 : 당뇨병 가족력 (pedigree)\n",
    "\n",
    "정보 8 : 나이 (age)\n",
    "\n",
    "​\n",
    "\n",
    "클래스 : 당뇨( 1) , 당뇨가 아님 ( 0 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train, test 셋으로 나눈 후 \n",
    "### 각각의 정확도를 구하시오.\n",
    "### test셋의 0번째 row 데이터로 당뇨병 유무를 확인하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df.iloc[:, :8]\n",
    "y_data = df.iloc[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 나누기\n",
    "x_train, x_test, y_train, y_test=train_test_split(x_data, y_data, test_size=0.2, random_state=1, stratify=y_data)\n",
    "\n",
    "# 분류에서는 stratify=y_data 을 꼭 줘야 함!!\n",
    "# 1, 0 균형을 잡도록 하는 옵션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규화 및 학습 파이프라인 설정\n",
    "model_logistic = make_pipeline( StandardScaler(), LogisticRegression() )\n",
    "model_logistic.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터 accuracy:  0.7752442996742671\n",
      "테스트데이터 accuracy:  0.7792207792207793\n"
     ]
    }
   ],
   "source": [
    "# 각 데이터셋의 정확도 추출\n",
    "print('학습데이터 accuracy: ',model_logistic.score(x_train,y_train))\n",
    "print('테스트데이터 accuracy: ',model_logistic.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test셋의 0번째 row에 대한 예측값\n",
    "model_logistic.predict([x_test.iloc[0,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logistic.predict(x_test.iloc[[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
